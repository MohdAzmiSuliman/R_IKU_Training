---
title: "Complex Sampling Design"
date: last-modified
date-format: "dddd, DD/MM/YYYY"
format: 
  html:
    theme: sandstone
    code-fold: show
    code-copy: hover
    code-overflow: wrap
    code-tools: true
    df-print: paged
    default-image-extension: svg
    embed-resources: true
    page-layout: full
    reference-location: margin
    title-block-banner: true
    title-block-style: default
    fontsize: 1.2em
    monofont: 'Fira Code'
number-sections: true
toc: true
fig-dpi: 320
dpi: 320
execute: 
  echo: fenced
---

# Introduction

## Complex Sampling Design


- **Census vs. Sampling**
   - Sampling is more feasible than a census, which attempts to reach everyone.
   - Sampling is less costly and time-consuming.
- **Random Sampling Limitations**
   - Purely random sampling may not adequately represent all groups, particularly minorities.
- **Stratified Sampling**
   - Stratification ensures that important subgroups within the population are adequately represented.
- **Cluster Sampling**
   - Clustering (e.g., by district or Enumeration Block) can increase efficiency, especially in geographically dispersed populations.
- **Adjustments in Complex Sampling**
   - Stratification and clustering alter initial selection probabilities.
   - Weight adjustments are necessary to equalize these probabilities.
- **Post-stratification**
   - Helps in aligning the sample estimates with the broader state or national populations.


- **NHMS Sampling Methodology**
   - Employs a two-stage stratified random sampling.
   - First stage: stratification by state.
   - Second stage: stratification by urban/rural locality.
   - Primary sampling unit: Enumeration Block; Secondary: Living Quarters.
- **Accounting for Design Effect**
   - Sample size needs to be inflated to accommodate the increased variance due to the complex design.


## Disclaimer

1. Limited exposure on complex sampling design
2. Mainly on verbal explanation and short reading
3. No formal training, and a lot of reverse engineering

# Practical


```{r}
#| label: setup
#| echo: false

pacman::p_load(tidyverse, janitor, summarytools, gtsummary, 
               broom, rstatix, ResourceSelection, pROC, caret, 
               survey)
```


## Setup your Project


1. Open your RStudio

2. Create Project
  - File -> New Project...
  - New Directory -> New Project
    - set Directory Name, e.g., `Sesi 4 NHMS`
    - ensure the project directory is in default working directory, i.e., `~/Documents/RStudio`
    - click `Create Project` button

3. Copy your NHMS dataset into the working directory
  - `Files` pane -> click the `âš™ï¸ More ðŸ”»` button -> select `Show Folder in New Window`
  - Copy your NHMS dataset into the working directory
  - alternatively, you can also check you working directory, and copy the working directory into your File Explorer

```{r}
#| eval: false
#| echo: true

getwd() %>% 
  clipr::write_clip()
```


## Create Quarto Document

1. Create Quarto Document
  - `File` -> `New File` -> `Quarto Document...`
2. Setup the new Quarto document
  - set title, e.g., `Sesi 4 - NHMS`
  - untick `use visual markdown editor`
  - click `Create Empty Document`
3. Update the YAML metadata to make the document self-contained

```{r}
#| echo: true
#| eval: false

---
title: "Sesi 4 - NHMS"
format:
  html:
    embed-resources: true

---

```

# Analysis

## Dataset Context

- Every analysis should have context
- In this practical session, these are the context
  - this practical is based on NHMS 2019 NCD dataset
  - we will focus on hypercholesterolaemia module of NHMS 2019
  - we will focus on known hypercholesterolaemia status - the column `known_chol` as the outcome

## Import Dataset

SPSS sav file.
  
  - Import the spss's sav file
    -   On the `Files` pane, click on the spss .sav file
  - Select `Import Dataset...`
  - Copy the code into r code chunk
  - add function `as_factor(_)` 
    - Note: as_factor (from `haven` package), 
    - **NOT** as.factor (from `base` package)

```{r}
library(tidyverse)
library(haven)

nhms19ds <- read_sav("nhms19ds.sav") %>% 
  as_factor()

nhms19ds %>% 
  select(-c(indvid, hh_id)) %>% 
  slice_sample(n = 30)
```

  - dont forget to briefly look at your data

```{r}
#| eval: false
#| echo: true

skimr::skim(nhms19ds)
```

  - since that we have missing data, especially at our intended outcome variable, filtering missing data will reduce our headache later.

```{r}
nhms19ds <- read_sav("nhms19ds.sav") %>% 
  as_factor() %>% 
  filter(!is.na(known_chol))
```


  - R and survey package can analyse the outcome variable `known_chol` eventhough it is categorical variable
  - the variable can also be numerical variable, but need to be in binary 0 and 1 form
  - for this practical session, we will convert to numerical and use the numerical variable


```{r}
nhms19ds <- read_sav("nhms19ds.sav") %>% 
  as_factor() %>% 
  filter(!is.na(known_chol)) %>% 
  mutate(known_cholN = as.numeric(known_chol)-2)
```



## Specifiying the Design

- In Complex Sampling Design, specifying the design is the first step. 
  - This is similar with CSPlan in SPSS
- Required information include

```{r}
#| echo: false

tribble(~`Required Information/Specification`, ~`Common NHMS Variable Name`, 
        "Cluster IDs", "EB ID", 
        "Strata", "State.Strata, State.wt", 
        "Sampling Weight", "ADW, weight_final, weight") %>% 
  gt::gt()
```


```{r}
nhms19ds %>% 
  select(-c(indvid, hh_id)) %>% 
  slice_sample(n = 30)
```


```{r}
nhms19ds %>% 
  select(-c(indvid, hh_id)) %>% 
  slice_sample(n = 30) %>% 
  select(ebid, state_st, state, strata_gp, wtfinal_ncd)
```

- In R, Complex Sampling Design Analysis was done with package `survey::`
  - `srvyr::` package bring parts of tidyverse syntax to survey analysis, using the `survey::` package
  - defining the design should be done in the first step
  - formula form is used in defining the design: **~** symbol
  - in addition, since our ebid is nested within strata, we need to add `nest` parameter

- this is the unweighted design

```{r}
library(survey)

nhms_unwdsg <- svydesign(id = ~1, 
                         weights = ~1, 
                         data = nhms19ds)
```

- and this is the weighted design

```{r}
library(survey)

nhms_surdsg <- svydesign(id = ~ebid, 
                         strata = ~state_st, 
                         weights = ~wtfinal_ncd, 
                         data = nhms19ds, 
                         nest = T)
```

- we may also want to add option if there is lonely PSU
  - i.e., single ebid in state.strata

```{r}
options(survey.lonely.psu = 'adjust', 
        survey.adjust.domain.lonely = TRUE)
```

- we can use function `summary(_)` to view our design

```{r}
summary(nhms_unwdsg)
```

```{r}
summary(nhms_surdsg)
```

## Estimating Known Hypercholesterolaemia

variable `known_cholN`


### Calculating Unweighted Count

- to calculate count (both unweigted and estimated population), `svytotal(_)` function from `survey::` package is used
  - for unweighted count, use unweighted design

```{r}
#| eval: false
#| echo: true

?svytotal
```


```{r}
svytotal(x = ~known_cholN,
         design = nhms_unwdsg, 
         na.rm = T)
```


```{r}
svytotal(x = ~known_chol,
         design = nhms_unwdsg, 
         na.rm = T)
```


### Calculating Estimated Population

- similar to unweighted count, for estimated population, we will use `svytotal(_)` function from `survey::` package
  - use weighted design

```{r}
svytotal(x = ~known_cholN,
         design = nhms_surdsg, 
         na.rm = T)
```


```{r}
svytotal(x = ~known_chol,
         design = nhms_surdsg, 
         na.rm = T)
```





### Calculating the Prevalence

- calculating prevalence using `svymean(_)` function from `survey::` package
  - variable can be coded as 0/1 or in factor form
  - check help page for further info

```{r}
#| eval: false
#| echo: true

?svymean
```

- in the help page, simplest `svymean(_)` function require
  - the variable that we want to calculate the prevalence (i.e. the variable `known_cholN`)
  - survey design (i.e. the `nhms_surdsg` object that contain the survey design)

```{r}
svymean(x = ~known_cholN,
        design = nhms_surdsg)
```


```{r}
svymean(x = ~known_chol,
        design = nhms_surdsg)
```



### Calculating the Confindence Interval

- generally, to extract the CI info, we can use `confint(_)` function, however special parameter have to specified because of how the CI is estimated
  - default `confint(_)` function use "mean" method, in which Wald-type interval calculated on the probability scale


```{r}
svymean(x = ~known_cholN,
        design = nhms_surdsg) %>% 
  confint()
```

- to change the CI estimate method, use `svyciprop(_)` from `survey::` package

```{r}
#| eval: false
#| echo: true

?svyciprop
```

- there was several method, but default method in R is "logit" method
- if we want to mimic SPSS and SUDAAN, use "xlogit" method

```{r}
svyciprop(formula = ~known_cholN, 
          design = nhms_surdsg) %>% 
  attr(., "ci")
```


```{r}
svyciprop(formula = ~known_cholN, 
          design = nhms_surdsg, 
          method = "lo") %>% 
  attr(., "ci")
```


```{r}
svyciprop(formula = ~known_cholN, 
          design = nhms_surdsg, 
          method = "xl") %>% 
  attr(., "ci")
```


## Subpopulation by State

- For subpopulation analysis, we use `svyby(_)` function, and specified the subset variable

```{r}
#| eval: false
#| echo: true

?svyby
```


### Unweighted count 
  
```{r}
svyby(formula = ~known_cholN, 
      by = ~state, 
      design = nhms_unwdsg, 
      FUN = svytotal, 
      na.rm.all = T)
```

### Estimated Population

```{r}
svyby(formula = ~known_cholN, 
      by = ~state, 
      design = nhms_surdsg, 
      FUN = svytotal, 
      na.rm.all = T)
```

### Prevalence

```{r}
svyby(formula = ~known_cholN, 
      by = ~state, 
      design = nhms_surdsg, 
      FUN = svymean, 
      na.rm.all = T)

```

### CI for Prevalence

- unfortunately, `svyciprop(_)` can't be use with `svyby(_)` function
  - need to subset manually
    - but when subset, the df is affected, thus need to specified using the overall design
    - add parameter `df = degf(design)`

```{r}
nhms_surdsg_johor <- subset(nhms_surdsg, 
                            state == "Johor") 

svyciprop(formula = ~known_cholN, 
          design = nhms_surdsg_johor, 
          method = "xl", 
          df = degf(nhms_surdsg)) %>% 
  attr(., "ci")
```

  - alternatively, we can either create custom function, or use loop


```{r}
svyciprop_by <- function(x, design, by) {
  by_var <- deparse(substitute(by))
  
  by_levels <- unique(design$variables[[by_var]])
  
  calculate_ci <- function(stratum) {
    subset_design <- subset(design, design$variables[[by_var]] == stratum)
    result <- svyciprop(x, design = subset_design, method = "xl", df = degf(design))
    return(attr(result, "ci"))
  }
  
  ci_results <- purrr::map(by_levels, calculate_ci)
  
  tibble::tibble(subset = by_levels, ci = ci_results) %>% 
    tidyr::unnest_wider(ci, names_sep = "_") %>% 
    dplyr::rename("Lower 95% CI" = "ci_2.5%", 
                  "Upper 95% CI" = "ci_97.5%")
}

svyciprop_by(x = ~known_cholN, design = nhms_surdsg, by = state)
```



## Logistic Regression

```{r}
svyglm(known_chol ~ strata_gp, nhms_surdsg, family = quasibinomial) %>% 
  summary()
```

```{r}
svyglm(known_chol ~ strata_gp, nhms_surdsg, family = quasibinomial) %>% 
  summary(exponentiate = T)
```



## Linear Regression

1. check again your dataset - the outcome variable is u303

```{r}
nhms19ds %>% 
  select(u303) %>% 
  slice_sample(n = 30)
```

2. in this example, the outcome is in categorical. convert to numerical

```{r}
nhms19ds_tc <- nhms19ds %>% 
  mutate(u303 = as.numeric(as.character(u303)))
```

3. redefine the survey design

```{r}
nhmstc_surdsg <- svydesign(id = ~ebid, 
                           strata = ~state_st, 
                           weights = ~wtfinal_ncd, 
                           data = nhms19ds_tc, 
                           nest = T)
```


```{r}
svyglm(u303 ~ strata_gp, nhmstc_surdsg, family = gaussian) %>% 
  summary()
```


# Bonus: Plot Malaysia Map

result can be use to plot Malaysia map.

1. save the prevalence by state into object to be used later

```{r}
kcprev_state <- svyby(formula = ~known_cholN, 
                      by = ~state, 
                      design = nhms_surdsg, 
                      FUN = svymean, 
                      na.rm.all = T) %>% 
  as_tibble()

kcprev_state
```

2. download state map (geojson file) from DOSM githhub page
  - and save into object to be used later

```{r}
#| eval: false
#| echo: true

download.file(
  url = "https://raw.githubusercontent.com/dosm-malaysia/data-open/main/datasets/geodata/administrative_1_state.geojson",
  destfile = "administrative_1_state.geojson",
  mode = "wb")
```

3. convert geojson file into r object, using `sf::` package

```{r}
library(sf)

read_sf("administrative_1_state.geojson")
```

  - since they have code_state, we can sort by code_state for us to check name


```{r}
read_sf("administrative_1_state.geojson") %>% 
  arrange(code_state)
```

  - rename the state using `fct_recode(_)` function
    - and save


```{r}
my_state_sf <- read_sf("administrative_1_state.geojson") %>% 
  arrange(code_state) %>% 
  mutate(state = fct_recode(state, 
                            "P. Pinang" = "Pulau Pinang", 
                            "N. Sembilan" = "Negeri Sembilan", 
                            "WP Kl" = "W.P. Kuala Lumpur", 
                            "WP Putrajaya" = "W.P. Putrajaya", 
                            "WP Labuan" = "W.P. Labuan"))


```

4. combine our result and the map file
  - convert into st object using `st_as_sf(_)` function
  - and save into object to be used later

```{r}
kcprev_state_mapds <- left_join(kcprev_state, my_state_sf) %>% 
  st_as_sf()

kcprev_state_mapds
```

5. plot with ggplot

```{r}
kcprev_state_mapds %>% 
  ggplot(aes(fill = known_cholN)) + 
  geom_sf()
```

6. we can also customised our plot - using esquisse addin

```{r}
ggplot(kcprev_state_mapds) +
  aes(fill = known_cholN) +
  geom_sf(size = 1.2) +
  scale_fill_viridis_c(option = "magma", direction = -1) +
  theme_void()
```



# Bonus: Plot Piramid Plot

# Bonus: Age-standardised
